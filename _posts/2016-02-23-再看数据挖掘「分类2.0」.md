---
layout: post
title: 再看数据挖掘--分类2.0
subtitle: 本系列属原创 转载请注明原著
date: 2016-02-23
author:     "Norris"
categories: blog
tags: [数据挖掘]
---

# 3.分类的组合方法

前文已经讲述了诸多分类的方法，决策树、神经网络、SVM、基于规则的分类器。这些都是一个单个的分类器，那么这节我们就来打破他们之间的界限，通过组合多个分类器来提高分类的准确性。这种技术称作组合，既然是个组合就得有个基分类器，然后通过对每个基分类器的预测进行投票来进行分类。

## 3.1 请问，为什么组合的更好？

思考一个问题，如果法官认为你有罪的概率是0.35，那么当你重复25个独立的法官（每个认为你有罪的概率都是0.35）在一起采取投票(超过一半法官认为你有罪的时候你就定罪）的方式决定你有罪的概率是多少呢？ $$\Sigma_{i=13}^{25}C^i_{25}\epsilon^i(1-\epsilon)^{25-i}=0.06$$

如果你不能理解上面这个例子，想象一下，把每个法官看做一个分类器，把判罪的概率看做分类器的错误率，那么是不是容易懂了呢？

可以看出组合分类器的性能高于基分类器。也不是时时刻刻都是这样的，这也需要条件：首先基分类器之前应该尽量相互独立，如果每个基分类器都完全一样，那么再怎么平均也都是徒劳。然后就是基分类器的误差率不能高于0.5，高于0.5就是说你不用分类器，瞎蒙一个的概率都比用这个分类器好...

## 3.2 这么好的方法如何构造呢？

简单地说就是在数据集上构造多个分类器，当输入未知样本做预测时，让这么多的分类器投票选择。具体一点说有以下几种方法：

1. 通过处理训练数据集。通过对原始数据抽样得到多个训练集，在每个训练集上建立一个分类器。常见的bagging和boosting。

2. 通过处理输入特征。通过选择输入特征的子集来形成每个训练集。对于含有大量冗余特征的数据集非常好用，常见的如随机森林。

3. 通过处理类标号。适用于类数足够多的情况。将类二分类，然后根据新的类建立分类器，然后重新二分类，再建立一个分类器，由此重复得到多个基分类器。常见的如：错误-纠正输出编码（error-correcting output coding）。

4. 通过处理学习算法。很多学习算法都有很多变种，例如神经网络，不同层数的隐藏层，不同的激活函数，不用的权值。将不同方法的分类器得到组合就是这种方法的思想。

组合方法对于不稳定的分类器效果很好。不稳定的分类器对于训练集的微小变化很敏感。例如基于规则的分类器、决策树、神经网络等。

## 3.3 Bagging

Bagging是一种根据均匀分布从数据集中重复抽样（有放回的）的技术。每个抽样的数据集都和原数据集一样大。和之前说过的Boosting类似，每个样本大约包含63.2%的原始数据。

在每个抽取的样本上执行一个基分类器，然后这时候来了一组陌生的数据，那么所有的基分类器就开个会，投票决定这个陌生的数据归属于哪一个类。Bagging为什么能提高分类的效果呢？因为它能够通过改善基分类器的方差来降低泛化误差。那么这也就说明，面对那些比较稳定的分类器，Bagging貌似不是一个好方法，因为稳定的分类器方差较小，一般偏倚较大。还有就是Bagging不太受过分拟合的影响。

## 3.4 Boosting

提升是一个迭代的过程，使用自适应的方法来改变训练样本的分布，使得基分类器聚集在那些很难分类的样本上。

简单的说Boosting的实现过程是：开始时，赋予每个样本同样的权值，使得他们等可能的被选作训练集。根据训练样本的抽样分布抽取一个新的样本集，然后在该训练集上训练一个分类器，并使用该分类器对原始数据中的**所有**样本进行分类。第二轮，将错误分类的样本提高权值，正确分类的样本减少权值，然后根据新的抽样分布抽取一个新的样本。重复以上过程即可。

Boosting有多种算法，主要区别在于权值更新的方法以及如何组合每个分类器。下面就介绍一下Adaboost。

Adaboost是常用的组合方法。以上的方法都是采用了多数投票选择的方法，那大家有没有想过，并不是每个分类器都是一样的好，就像玩狼人杀一样，村长这种重要角色是有两票的，而普通村民只有一票。所以Adaboost首先定义了每个分类器的重要性。重要性如何体现呢？误差率越小的基分类器，重要性就越高。可以看一下这些优美的公式。

误差率：

$$\varepsilon_i=\frac{1}{N}[\Sigma^N_{j=1}w_jI(C_i(x_j)\neq y_i)]$$

其中p为一个示性函数。

基分类器$$C_i$$的重要性如下：

$$\alpha_i=\frac{1}{2}ln(\frac{1-\varepsilon_i}{\varepsilon_i})$$

为什么优美呢？大家可以把重要性的曲线图画出来。不仅如此，好不容易算出来的重要性，还可以用到权值的更新中！

$$w_i^{j+1}=\frac{w_i^{(j)}}{Z_j}\times \begin{equation}
\left\{
\begin{aligned}
e^{-\alpha_j} 如果 C_j(x_i)=y_i \\
e^{\alpha_j}  如果 C_j(x_i)\neq y_i \\
\end{aligned}
\right.
\end{equation}$$

其中$$Z_j$$是一个正规因子，用来确保取值之和为1。

尽管Adaboosting有种种的优势，但是他总是趋于错误分类的样本，很容易导致过分拟合的影响。

## 3.5 随机森林

随机森林，有没有一种宠物小精灵进化的感觉？随机树到随机森林！其实随机森林就是一种专门为决策树分类器设计的组合方法。

随机森林与Bagging Adaboosting不同，他不抽选样本了，他抽选变量。从很多属性中随机选取一部分作为一个样本集，然后根据这些属性进行决策树分类，重复以上过程，得到多个基分类器。

选取属性集的方法大概有三种：

1. 第一种是随机的选择F个特征，进行决策树分类。通常$$F=log_2d+1$$，d是输入特征数。这种方法称为Forest-RI。
2. 第二种方法面对特征数d比较小的情况。没有条件我们就创造条件，将不同属性的线性组合作为新的特征加入到抽样的过程中。这种方法称为Forest-RC。
3. 第三种方法是，在决策树的每个结点，从F个最佳划分中随机选择一个。除非F非常大，否则这种方法会构建相关性更强的（相比于前两种）的树。

随机森林的性能取决于两点，一个是一组分类器的强度（即分类器的平均性能，能够正确预测给定样本的可能性），以及树之间的相关性。相关性越小，随机森林的性能越好。

随机森林的分类准确率可以与Adaboost相媲美，而且对噪声有更好的鲁棒性，并且计算速度更快。

# 4.不平衡类的问题

不平衡类的问题是十分常见的，比如信用卡欺诈、不合格产品检验等等。这些问题中，稀有类分类的准确率往往更有价值，然而由于是不平衡的问题，我们上面说过的分类器有可能就会出现问题。

## 4.1 不平衡类的度量

首先我们来来看看之前我们都是如何评价一个分类器的性能的，最常用的就是准确率了。那么对于不平衡类的问题，是否准确率能反映问题呢？想象这样一个场景，我们的银行系统预测信用卡合法交易的准确率是99%，但是只有1%的客户可能会有诈骗行为存在，那么这个模型可以说性能好吗？显然是不准确的。

那么我们就来看看如何度量不平衡类问题的分类器性能。

准确率度量将每个类看的同等重要，不适合分析不平衡类的问题。不平衡类问题中稀有类通常记为正类，而多数类记为负类。通常有如下混淆矩阵：

|  |  |预测的类|预测的类|
|--|--|--|--|
|   |   | + | - |
|实际的类|+|$$f_{++}(TP)$$|$$f_{+-}(FN)$$|
|实际的类|-|$$f_{-+}(FP)$$|$$f_{--}(TN)$$|

TP:True Positive 正确分类到正类中的正样本数

FP:False Positive 错误分类为正类的负样本数

TN:True Negative 正确分类到负类中的负样本数

FN:False Negative 错误分到负类中的正样本数

真正率（TPR,True positive rate）或者叫灵敏度（sensitivity）定义为被正确预测的正样本比例：

$$TPR=\frac{TP}{(TP+FN)}$$

真负率（TNR,True negative rate）或叫做特指度（specificity）定义为正确预测的负样本比例：

$$TNR=\frac{TN}{(TN+FP)}$$

同理假正率、假负率就预测为正类的负样本比例和预测为负样本的正样本比例。

重要的是一下概念：

召回率（recall）和精度（precision）。

精度$$p=\frac{TP}{TP+FP}$$

召回率$$r=\frac{TP}{TP+FN}$$

精度为分为正类中真正为正类的比例，而召回率是所有正类样本被真正预测出来的比例。

如何兼顾精确率和召回率呢，构建他们的调和平均数，即$$F_1$$度量。

$$F_1=\frac{2}{\frac{1}{r}+\frac{1}{p}}$$

更一般的有$$F_\beta$$度量

接下来就是分类器非常常用的一个评价标准，ROC（receiver operating characteristic）接受者操作特征曲线。它以真正率作为纵轴，假正率作为横轴，曲线中每个点对应一个基分类器。

对于ROC曲线，越靠近左上角的曲线越好（真正率高，假正率低）。一个随机猜测的分类器的ROC曲线是从左下角到右上角的一条直线，如果分类器的曲线低于这个曲线的话，那么这个分类器是十分差劲的（还不如瞎猜的概率高）。还有一种评判方式是通过AUC(area under roc)来评价，AUC越大说明分类器的性能越好。

## 4.2 代价敏感学习

 既然已经知道用什么度量来评价不平衡类的问题了，那么具体怎么构建模型呢。就是这节的标题，代价敏感学习。首先说下代价矩阵，类似混淆矩阵，代价矩阵给每个分类情况一个编码，根据不同的情况，给予不同的权值，例如TP的情况我们可以给予-1的编码，FN的情况就比较严重了，给予它100的编码，而FP得情况，还可以接受，给予+1的编码，而TN无所谓了，我们就给与他0的编码，编码的大小代表错误的代价。用不同的编码乘以相应的TPR,TNR,FPR,FNR等等，可以得到整个模型总代价：

 $$C_t(M)=TP\times C(+,+)+FP\times C(-,+)+FN\times C(+,-)+TN\times C(-,-)$$

 其中$$C(i,j)$$表示预测一个i类记录为j类的代价。

 如何将这种代价信息加入到模型中间去呢？

 例如在决策树的过程中：可以用作选择分类数据的最好属性。决定子树是否需要剪枝。决定权值的收敛。修改每个叶节点上的决策规则。


## 4.3 基于抽样的方法

上面的方法是不是稍显麻烦呢？来看看从根源的角度上解决这个问题的方法（不一定会比代价敏感学习的方法好）。简单来说，不平衡类就是因为正样本太少，负样本太多。那么我们就这么做，正样本多抽一些，负样本少抽一些，使得二者达到一个平衡。需要用到两种技术：

1. 不充分抽样（undersampling）。取负样本的一个随机抽样，与正样本混合产生新的数据集。这个方法一个明显的缺点就是可能会把有用的负样本记录删除掉。怎么解决呢？多次执行（类似组合方法的思想）或者使用聚焦的不充分抽样，即明确的排除一些负样本，如那些离决策边界很远的样本。

2. 过分抽样。不断抽正样本，使得正样本数与负样本达到一个平衡。或者产生新的正样本，例如找到一个正样本的一个最邻近正样本点，然后在他们的连线中随机取一点作为新的正样本记录。当然，如果存在噪音数据的话，会导致模型的过分拟合。

既然都有缺点，不如折中一下，将两个方法混合，一起用。对正样本进行过分抽样，负样本进行不充分抽样就好了！

# 5.多类问题

前面大多数的分类方法都侧重于二分类的问题，但是现实往往是残酷的，你得面对多分类的情况。怎么解决呢？

1. 将多分类问题分解，每一将其中一个类定义为正类，其他为负类，对所有类都这么做一遍，每一遍做一个分类器，然后就投票吧。或者将输出映射到一个概率空间，然后选出最大概率的类。（这样做是为了减少平局的可能）

2. 与多分类问题中的每一对类都构建一个分类器。这个更复杂。

3. 纠正输出编码（error-correcting output coding, ECOC）。前面两种方法对于错误都十分敏感，所以就出现了ECOC。简单来说就是给一个类一个长度相同的编码，有点类似二进制转化的思想。不过这个编码是通过信息论的理论确定的。然后对编码中每一个二进制做一个二分类器即可。