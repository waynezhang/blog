---
layout: post
title: 异常值&强影响点
subtitle: 
date: 2016-10-18
author:     "Norris"
categories: blog
tags: [Statistic]
---


# 异常值（Outlier）

## 1.概念

> In statistics, an outlier is an observation point that is distant from other observations.[1][2] An outlier may be due to variability in the measurement or it may indicate experimental error; the latter are sometimes excluded from the data set.[3]

> Outliers can occur by chance in any distribution, but they often indicate either measurement error or that the population has a heavy-tailed distribution. In the former case one wishes to discard them or use statistics that are robust to outliers, while in the latter case they indicate that the distribution has high skewness and that one should be very cautious in using tools or intuitions that assume a normal distribution. A frequent cause of outliers is a mixture of two distributions, which may be two distinct sub-populations, or may indicate 'correct trial' versus 'measurement error'; this is modeled by a mixture model.

> In most larger samplings of data, some data points will be further away from the sample mean than what is deemed reasonable. This can be due to incidental systematic error or flaws in the theory that generated an assumed family of probability distributions, or it may be that some observations are far from the center of the data. Outlier points can therefore indicate faulty data, erroneous procedures, or areas where a certain theory might not be valid. However, in large samples, a small number of outliers is to be expected (and not due to any anomalous condition).

>Outliers, being the most extreme observations, may include the sample maximum or sample minimum, or both, depending on whether they are extremely high or low. However, the sample maximum and minimum are not always outliers because they may not be unusually far from other observations.

>Naive interpretation of statistics derived from data sets that include outliers may be misleading. For example, if one is calculating the average temperature of 10 objects in a room, and nine of them are between 20 and 25 degrees Celsius, but an oven is at 175 °C, the median of the data will be between 20 and 25 °C but the mean temperature will be between 35.5 and 40 °C. In this case, the median better reflects the temperature of a randomly sampled object than the mean; naively interpreting the mean as "a typical sample", equivalent to the median, is incorrect. As illustrated in this case, outliers may indicate data points that belong to a different population than the rest of the sample set.

>Estimators capable of coping with outliers are said to be robust: the median is a robust statistic of central tendency, while the mean is not.

以上来自wiki百科的概念，总结来说是：异常值是与其他观测值差别较大的观测值。

异常值来自于三个可能：

1. 测量误差

2. 分布的厚尾

3. 一个混合分布的正常取值

第一种情况一般将这种异常值去除或者采用高robust的模型来做拟合，后面两种情况就需要选择或者分解出对的分布来拟合这些异常值的出现。

在大样本情况下，异常值的出现时非常正常的情况。但是过于天真的去解释异常值的出现是错误的做法，因为异常的来源上面也说过了，不仅仅是只需剔除掉那么简单的问题。


## 2.异常值的分类

异常值的种类也可以分成三类：

1. Point outliers

	![Point outliers](https://upload.wikimedia.org/wikipedia/commons/thumb/0/07/Two-dimensional_Outliers_Example.png/440px-Two-dimensional_Outliers_Example.png)

	An example of a contextual outlier. Points labeled t1 and t2 represent the same temperature value. Though, point t2 is considered an outlier, while point t1 is not.Example of two-dimensional outliers. Point labeled O1 and points labeled O2 deviate significantly from regions labeled G1 and G2.

	> If an individual data point can be considered anomalous with respect to the rest of the data, then the datum is termed as a point outlier. This is the simplest type of outlier and it is the focus of the majority of research on outlier detection. For example, in Figure above, points labeled O1 and O2 are typical point outliers since they are significantly different from the normal data points in regions G1 and G2.

	这是最常见的异常点的类型，如上图所示。


2. Contextual outliers

	![Contextual outliers](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Contextual_Outlier.png/440px-Contextual_Outlier.png)

	An example of a contextual outlier. Points labeled t1 and t2 represent the same temperature value. Though, point t2 is considered an outlier, while point t1 is not.

	> If an individual data instance is anomalous in a specific context (but not otherwise), then it is termed as a contextual (conditional) outlier. The notion of a context is induced by the structure of the data set and has to be specified as a part of the problem formulation. Each data point is defined with two sets of attributes:

	> * Contextual attributes, which are used to determine the context (or neighbourhood) for that instance; for example, time in time-series data, or longitude and latitude in spatial data sets.

	> * Behavioral attributes, which are used to define other characteristics of the data point, specific to the problem in hand; for example, number of sales at the specific location.

	> Contextual outliers are detected using the values for the behavioral attributes in a specific context. Therefore, a data point might be an outlier in a given context, but could be considered normal in a different context.

	>These types of outliers have normally been explored in time-series data and spatial data.

	这种异常点通常出现在时序或者空间数据中，是在一定条件下视作异常值的类型。

3. Collective outliers

	![Collective outliers](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/Collective_Outlier.png/440px-Collective_Outlier.png)

	An example of the collective outlier in the human electrocardiogram.
	
	> If a collection of data points is anomalous with respect to the entire data set, it is termed as a collective outlier. The individual data points inside the collective outlier may not be outliers by themselves alone, but their occurrence together as a collection is anomalous. Collective outliers can occur only in data sets in which data points are somehow related. For example, Figure 4 shows a human electrocardiogram output. Values in the range [5000, 7000] represent a collective outlier because the same low value exists for an abnormally long time. The low value itself is not an outlier, but its successive occurrence for long time is.

	跟上一种类型相似，不过是根据不同的数据集而看，例如图中例子，[5000, 7000]内的数据就是异常值，因为人类的心电图不可能在长时间达到这个值。

## 3.异常值的发生

> In the case of normally distributed data, the three sigma rule means that roughly 1 in 22 observations will differ by twice the standard deviation or more from the mean, and 1 in 370 will deviate by three times the standard deviation.[6] In a sample of 1000 observations, the presence of up to five observations deviating from the mean by more than three times the standard deviation is within the range of what can be expected, being less than twice the expected number and hence within 1 standard deviation of the expected number – see Poisson distribution – and not indicate an anomaly. If the sample size is only 100, however, just three such outliers are already reason for concern, being more than 11 times the expected number.

> In general, if the nature of the population distribution is known a priori, it is possible to test if the number of outliers deviate significantly from what can be expected: for a given cutoff (so samples fall beyond the cutoff with probability p) of a given distribution, the number of outliers will follow a binomial distribution with parameter p, which can generally be well-approximated by the Poisson distribution with λ = pn. Thus if one takes a normal distribution with cutoff 3 standard deviations from the mean, p is approximately 0.3%, and thus for 1000 trials one can approximate the number of samples whose deviation exceeds 3 sigmas by a Poisson distribution with λ = 3.

前面说过异常值的出现是正常的，不过如果已知了数据的分布，我们可以计算出出现的异常值的次数是否合理，这就用到了[68–95–99.7 rule](https://en.wikipedia.org/wiki/68–95–99.7_rule)的原理。


## 4.异常值的检测

> There is no rigid mathematical definition of what constitutes an outlier; determining whether or not an observation is an outlier is ultimately a subjective exercise. There are various methods of outlier detection. Some are graphical such as normal probability plots. Others are model-based. Box plots are a hybrid.

[more](https://en.wikipedia.org/wiki/Outlier)

## 5.如何处理异常值

> The choice of how to deal with an outlier should depend on the cause.

1. Retention

	> Even when a normal distribution model is appropriate to the data being analyzed, outliers are expected for large sample sizes and should not automatically be discarded if that is the case. The application should use a classification algorithm that is robust to outliers to model data with naturally occurring outlier points.

	当异常值的存在视为合理时，保留它并选用高鲁棒性的模型。

2. Exclusion

	> Deletion of outlier data is a controversial practice frowned upon by many scientists and science instructors; while mathematical criteria provide an objective and quantitative method for data rejection, they do not make the practice more scientifically or methodologically sound, especially in small sets or where a normal distribution cannot be assumed. Rejection of outliers is more acceptable in areas of practice where the underlying model of the process being measured and the usual distribution of measurement error are confidently known. An outlier resulting from an instrument reading error may be excluded but it is desirable that the reading is at least verified.

	> The two common approaches to exclude outliers are truncation (or trimming) and Winsorising. Trimming discards the outliers whereas Winsorising replaces the outliers with the nearest "nonsuspect" data.[22] Exclusion can also be a consequence of the measurement process, such as when an experiment is not entirely capable of measuring such extreme values, resulting in censored data.[23]

	> In regression problems, an alternative approach may be to only exclude points which exhibit a large degree of influence on the estimated coefficients, using a measure such as Cook's distance.[24]

	> If a data point (or points) is excluded from the data analysis, this should be clearly stated on any subsequent report.

	剔除异常值是一个非常有争议的问题，当确定的测量误差存在时，剔除异常值是一种可以接受的做法，剔除异常值有两种做法：删除和替换，前者直接从样本集中删掉异常点，而后者用最真实的值来替代异常点。在回归分析中通常用COOK距离来测量异常值。

3. Non-normal distributions

	> The possibility should be considered that the underlying distribution of the data is not approximately normal, having "fat tails". For instance, when sampling from a Cauchy distribution,[25] the sample variance increases with the sample size, the sample mean fails to converge as the sample size increases, and outliers are expected at far larger rates than for a normal distribution. Even a slight difference in the fatness of the tails can make a large difference in the expected number of extreme values.

	当分布不是正太分布而是某种厚尾分布时，异常值的出现是可以接受的，因此反过来说，如果接受了异常值的存在，或者认为潜在的分布不是正太分布时，应该用某种厚尾分布替代（例如柯西分布）。

4. Set-membership uncertainties

	> A set membership approach considers that the uncertainty corresponding to the ith measurement of an unknown random vector x is represented by a set Xi (instead of a probability density function). If no outliers occur, x should belong to the intersection of all Xi's. When outliers occur, this intersection could be empty, and we should relax a small number of the sets Xi (as small as possible) in order to avoid any inconsistency.[26] This can be done using the notion of q-relaxed intersection. As illustrated by the figure, the q-relaxed intersection corresponds to the set of all x which belong to all sets except q of them. Sets Xi that do not intersect the q-relaxed intersection could be suspected to be outliers.

	[more](https://en.wikipedia.org/wiki/Set_estimation)


5. Alternative models

	> In cases where the cause of the outliers is known, it may be possible to incorporate this effect into the model structure, for example by using a hierarchical Bayes model or a mixture model.

	当数据集的来源不是某一个分布而是一个混个混合分布的时候（例如两个方差差别很大的高斯混合分布）就很可能差生异常值。当我们确定了数据的异常值是来自于分布结构的问题时，通常采用这种做法。


# 强影响点

强影响点与异常值是否是两个概念呢？查到的资料也没有明确的说，不过这也不是重点。追根溯源，强影响点其实针对的是回归模型中对回归影响较大的点。什么是对回归影响较大的点？可分为三种情况：

1. 对回归的样本集”影响较大“的点（与其说影响大不如说成远离其他点的观测值）

2. 对估计值($\hat{y})影响较大的点

3. 对(单个或整体）回归系数影响较大的点

针对不同的情况我们有不同的判断方式：

1. 针对第一种类型我们选用Leverage（杠杆率）来衡量一个观测与其他观测值的”远近“程度。一个高Leverage值是极端或者外围的值，并且会使得拟合的回归非常接近这些高Leverage的点。在R中做线性回归plot的时候会经常看到一个图是 residuals vs.  leverage 的图，用来识别异常值点的图。那么 residuals 和 leverage 之间有什么联系呢？答案就在 Studentized residuals 之中。

	$$ t_i = \frac{e_i}{\hat{\sigma}\sqrt{1-h_{ii}}} $$ 

	从上式中也可以看出，如果杠杆率以及残差非常大，即他不仅对样本集的影响非常大，而且对回归的影响也非常大，那么这个值非常有可能是一个异常值（这里可以加上cook距离一起判断，事实上在R回归的图形中也就是这样做的）。

	tips: 其实杠杆率和马氏距离非常接近，只相差一个量级，感兴趣的同学可以看[这里](https://en.wikipedia.org/wiki/Mahalanobis_distance#Relationship_to_leverage)

2. 针对第二种情况，我们可以采用[DFFITS](https://en.wikipedia.org/wiki/DFFITS)，该参数衡量的是去除某个观测值时拟合值得变化程度。

	$$ DFFITS = \frac{\hat{y_i}-\hat{y_{i(i)}}}{s_{(i)}\sqrt{h_{ii}}} $$

	公式具体含义请移步链接[DFFITS](https://en.wikipedia.org/wiki/DFFITS)。

	DFFITS其实和 Studentized residuals 是一样的，相差一个系数$$\sqrt{h_{ii}/(1-h_{ii})}$$而已。

	从公式中可以看出，低杠杆率的观测值其DFFITS值也是极小的，而当Leverage值接近于其上限1的时候，DFFITS的值变为无穷大。

	通过实验验证，一个分布极度平衡的样本集，期每个观测值的Leverage值都是 p/n ，即每个参数均匀的分配在每个样本点上（p是参数格式，n是样本观测值个数），所以DFFITS应该是t残差的$$\sqrt{\frac{p}{n-p}} \approx \frac{p}{n}$$倍。

	因此一般将DFFITS超过$$2\frac{p}{n}$$的值判定为异常值。

	尽管与接下来要说的cook距离在公式上不同，但是这两者的概念是一致的，而且其公式也是可以通过近似相互转化。

3. 针对第三种情况来说，首先如果看单个参数的影响，我们采用DFBETA来衡量。DFBETA的含义是去除某个观测值时每个参数的变化程度。

	$$ DFBETA_i = b - b_{-i} = \frac{(X^TX)^{-1}x_i^Te_i}{1-h_i} $$

	从公式中可以直观的看出其定义，详细内容移步[这里](https://en.wikipedia.org/wiki/Influential_observation)

	如果相关差所有参数的影响，就要使用一直在说的COOK距离。

	$$ D_i = \frac{e_i^2}{s^2p}[\frac{h_i}{(1-h_i)^2}] $$

	COOK距离综合考虑了杠杆率以及残差的大小，最简单的去除标准是 $$D_i > 1$$，另外如果样本量较大，可以考虑使用 $$D_i > \frac{4}{n}$$作为标准。

	还有一个更为保守的做法是利用WALD检验，详情请见[这里](https://en.wikipedia.org/wiki/Cook%27s_distance)

**Wiki上一句话作为总结：**

>[An outlier may be defined as a surprising data point. Leverage is a measure of how much the estimated value of the dependent variable changes when the point is removed. There is one value of leverage for each data point. Data points with high leverage force the regression line to be close to the point.](https://en.wikipedia.org/wiki/Influential_observation)

## simple example

![小解释](/images/2016/10/explain.png)
![小例子](/images/2016/10/example_png.png)

A点：非异常点、高杠杆点、非强影响点

	A点在X空间中距离样本的中心较远，A是个高杠杆点；
	A点的位置在通过其他点的直线附近，残差很小，对拟合回归方程没有很大的影响，A点不是异常点也不是强影响点。
	B点：异常点、非高杠杆点、强影响点

B点在X空间中距离样本的中心较近，B不是高杠杆点；
	
	B点的残差很大，是异常点也是强影响点；
	注意：B点的存在没有改变拟合直线的斜率，但是改变了拟合直线的截距。
	C点：异常点、高杠杆点、强影响点

C点的残差很大，所以点是一个异常点；

	C点在方向上远离其它的点的中心，所以点是一个高杠杆点；
	C点的引入实质性的改变拟合回归方程的特征，所以它是一个强影响点。


	





